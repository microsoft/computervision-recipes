{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a Multi-Object Tracking Model on MOT Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for evaluating [FairMOT](https://github.com/ifzhang/FairMOT) on the [MOT Challenge dataset](https://motchallenge.net/), one of the most common benchmarking datasets for measuring multi-object tracking performance on pedestrian data. The collection includes MOT15, MOT16/17, and MOT 19/20. These datasets contain various video sequences, each with different tracking difficulty levels and ground-truth annotations. Detections are also provided for optional use.\n",
    "\n",
    "The goal of this notebook is to re-produce published results on the MOT challenge using the state-of-the-art FairMOT approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure edits to libraries are loaded and plotting is shown in the notebook.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchVision: 0.4.0a0+6b959ee\n",
      "Torch is using GPU: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from urllib.parse import urljoin\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from utils_cv.common.data import data_path, download, unzip_url\n",
    "from utils_cv.common.gpu import which_processor, is_windows\n",
    "from utils_cv.tracking.data import Urls\n",
    "from utils_cv.tracking.dataset import TrackingDataset\n",
    "from utils_cv.tracking.model import TrackingLearner\n",
    "\n",
    "# Change matplotlib backend so that plots are shown for windows\n",
    "if is_windows():\n",
    "    plt.switch_backend(\"TkAgg\")\n",
    "\n",
    "print(f\"TorchVision: {torchvision.__version__}\")\n",
    "which_processor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows your machine's GPUs (if it has any) and the computing device `torch/torchvision` is using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set some model runtime parameters. We evaluate the FairMOT model on MOT17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch device: cuda\n"
     ]
    }
   ],
   "source": [
    "CONF_THRES = 0.4\n",
    "TRACK_BUFFER = 30\n",
    "IM_SIZE = (1080, 1920)\n",
    "\n",
    "# Downloaded MOT Challendage data path\n",
    "MOT_ROOT_PATH = \"../../data/\"\n",
    "RESULT_ROOT = \"./results\"\n",
    "EXP_NAME = \"MOT_val_all_dla34\"\n",
    "\n",
    "BASELINE_MODEL = \"./models/all_dla34.pth\"\n",
    "MOTCHALLENGE_BASE_URL = \"https://motchallenge.net/data/\"\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using torch device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [MOT17](https://motchallenge.net/data/MOT17.zip) data to `MOT_SAVED_PATH`. The MOT17 dataset is around 5GB. Note that it may take some time to download.\n",
    "\n",
    "Since MOT17 provides ground truths in the training data, we evaluate FairMOT on it by [py-motmetrics](https://github.com/cheind/py-motmetrics). For evaluating on testing dataset, see 'Evaluate on Test Set' section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved to ../../data/MOT17/train\n",
      "Test data saved to ../../data/MOT17/test\n"
     ]
    }
   ],
   "source": [
    "mot_path = urljoin(MOTCHALLENGE_BASE_URL, \"MOT17.zip\")\n",
    "MOT_TRAIN_PATH = osp.join(MOT_ROOT_PATH, \"MOT17\", \"train\")\n",
    "MOT_TEST_PATH = osp.join(MOT_ROOT_PATH, \"MOT17\", \"test\")\n",
    "# seqs_str:  various video sequences subfolder names under MOT challenge data\n",
    "train_seqs_str = \"\"\"MOT17-02-SDP\n",
    "                    MOT17-04-SDP\n",
    "                    MOT17-05-SDP\n",
    "                    MOT17-09-SDP\n",
    "                    MOT17-10-SDP\n",
    "                    MOT17-11-SDP\n",
    "                    MOT17-13-SDP\"\"\"\n",
    "test_seqs_str = \"\"\"MOT17-01-SDP\n",
    "                   MOT17-03-SDP\n",
    "                   MOT17-06-SDP\n",
    "                   MOT17-07-SDP\n",
    "                   MOT17-08-SDP\n",
    "                   MOT17-12-SDP\n",
    "                   MOT17-14-SDP\"\"\"\n",
    "\n",
    "unzip_url(mot_path, dest=MOT_SAVED_PATH, exist_ok=True)\n",
    "print(f\"Training data saved to {MOT_TRAIN_PATH}\")\n",
    "print(f\"Test data saved to {MOT_TEST_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and load the model. We use the pre-trained baseline FairMOT model - `all_dla34.pth`, which can be downloaded [here](https://drive.google.com/file/d/1udpOPum8fJdoEQm6n0jsIgMMViOMFinu/view). Please upload and save `all_dla34.pth` to `BASELINE_MODEL` path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = TrackingLearner(None, BASELINE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use training dataset from MOT17 to evaluate with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-02-SDP.txt\n",
      "Evaluate seq: MOT17-02-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-04-SDP.txt\n",
      "Evaluate seq: MOT17-04-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-05-SDP.txt\n",
      "Evaluate seq: MOT17-05-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-09-SDP.txt\n",
      "Evaluate seq: MOT17-09-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-10-SDP.txt\n",
      "Evaluate seq: MOT17-10-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-11-SDP.txt\n",
      "Evaluate seq: MOT17-11-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-13-SDP.txt\n",
      "Evaluate seq: MOT17-13-SDP\n",
      "              IDF1   IDP   IDR  Rcll  Prcn  GT  MT  PT ML    FP    FN IDs    FM  MOTA  MOTP IDt IDa IDm\n",
      "MOT17-02-SDP 60.1% 68.9% 53.3% 72.3% 93.4%  62  28  25  9   950  5148 243   628 65.9% 0.198 138  49  16\n",
      "MOT17-04-SDP 83.2% 85.1% 81.2% 86.3% 90.4%  83  51  21 11  4348  6526  32   219 77.1% 0.172   6  20   1\n",
      "MOT17-05-SDP 73.1% 75.5% 70.9% 83.9% 89.2% 133  74  50  9   702  1117 120   217 72.0% 0.221 100  45  41\n",
      "MOT17-09-SDP 65.9% 71.6% 61.0% 81.5% 95.7%  26  18   8  0   197   984  45   105 77.0% 0.175  34  10   7\n",
      "MOT17-10-SDP 63.5% 68.4% 59.2% 79.0% 91.3%  57  30  27  0   970  2700 182   439 70.0% 0.233 109  44  14\n",
      "MOT17-11-SDP 82.2% 82.0% 82.4% 92.3% 91.9%  75  55  16  4   764   722  75   112 83.5% 0.171  29  34   9\n",
      "MOT17-13-SDP 64.6% 65.9% 63.3% 77.2% 80.3% 110  50  51  9  2203  2658 164   457 56.8% 0.279  97  39  42\n",
      "OVERALL      73.9% 77.5% 70.7% 82.3% 90.1% 546 306 198 42 10134 19855 861  2177 72.5% 0.196 513 241 130\n"
     ]
    }
   ],
   "source": [
    "seqs = [seq.strip() for seq in train_seqs_str.split()]\n",
    "\n",
    "strsummary = tracker.eval_mot(\n",
    "    conf_thres=CONF_THRES,\n",
    "    track_buffer=TRACK_BUFFER,\n",
    "    im_size=IM_SIZE,\n",
    "    data_root=MOT_TRAIN_PATH,\n",
    "    seqs=seqs,\n",
    "    result_root=RESULT_ROOT,\n",
    "    exp_name=EXP_NAME,\n",
    ")\n",
    "print(strsummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reported evaluation results from [FairMOT paper](https://arxiv.org/abs/2004.01888) with test set are as follows:\n",
    "\n",
    "| Dataset | MOTA   | IDF1 | IDS | MT | ML | FPS |\n",
    "|------|------|------|------|------|------|------|\n",
    "|   MOT16  | 68.7| 70.4| 953| 39.5%| 19.0%| 25.9|\n",
    "|   MOT17  | 67.5| 69.8| 2868| 37.7%| 20.8%| 25.9|\n",
    "\n",
    "For evaluating on testing dataset, you can get the txt prediction results in this section and submit to the [MOT Challenge](https://motchallenge.net/) evaluation server to obtain the results. You can get the SOTA results 68.5 MOTA on MOT17 test set using the baseline model 'all_dla34.pth' from the [MOT17 evaluation server](https://motchallenge.net/results/MOT17/?det=Private).\n",
    "<img src=\"media/mot_results.PNG\" style=\"width: 737.5px;height: 365px\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-01-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-03-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-06-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-07-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-08-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-12-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-14-SDP.txt\n"
     ]
    }
   ],
   "source": [
    "seqs = [seq.strip() for seq in test_seqs_str.split()]\n",
    "\n",
    "tracker.eval_mot(\n",
    "    conf_thres=CONF_THRES,\n",
    "    track_buffer=TRACK_BUFFER,\n",
    "    im_size=IM_SIZE,\n",
    "    data_root=MOT_TEST_PATH,\n",
    "    seqs=seqs,\n",
    "    result_root=RESULT_ROOT,\n",
    "    exp_name=EXP_NAME,\n",
    "    if_test_data=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "356.263px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
